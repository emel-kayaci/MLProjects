{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNci3SsyOvpk"
   },
   "source": [
    "# Project - Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oGkFF4WOxAD"
   },
   "source": [
    "Hola !\n",
    "\n",
    "Objective of this project is to implement the following models for the CIFAR100 image classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4u-hdsQCOjF8"
   },
   "source": [
    "### Importing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KqKvuMOvPVgo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4DYSrBqPYGV"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7RSfrtKYYfWm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# channels first: 3 (rgb images) x 32 x 32\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    # number of examples, channels, rows, columns\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    # 28 x 28 x 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "# normalize data     \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oivf0DssOjGE"
   },
   "source": [
    "###  Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X-sPYR9sOjGF"
   },
   "outputs": [],
   "source": [
    "# Mention the training parameters such as epochs, learning rate, number of samples etc.\n",
    "batch_size = 128\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2Iopu5yZd09"
   },
   "source": [
    "## Training CNN for CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7Nab-y7IaI2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 206,468\n",
      "Trainable params: 206,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Design the model architecture here\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYHgAO4Qbxdc"
   },
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GypCNf5Obysn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.0497 - accuracy: 0.9900 - val_loss: 0.0453 - val_accuracy: 0.9901\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 0.0431 - accuracy: 0.9902 - val_loss: 0.0411 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2339c3d0908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model architecture here\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjfLW20PasaS"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7DReRBpjatbG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Train the transfer learning model here\n",
    "pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[32,32, 3])\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDFQd0XPawr1"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 37s 4ms/sample - loss: 0.0647 - acc: 0.0415\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 35s 4ms/sample - loss: 0.0464 - acc: 0.1897\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 35s 3ms/sample - loss: 0.0381 - acc: 0.3057\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 34s 3ms/sample - loss: 0.0321 - acc: 0.4105\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 35s 3ms/sample - loss: 0.0277 - acc: 0.5079\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 35s 4ms/sample - loss: 0.0243 - acc: 0.5840\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 34s 3ms/sample - loss: 0.0215 - acc: 0.6429\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 35s 4ms/sample - loss: 0.0192 - acc: 0.6974\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 33s 3ms/sample - loss: 0.0173 - acc: 0.7398\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 32s 3ms/sample - loss: 0.0157 - acc: 0.7749\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 33s 3ms/sample - loss: 0.0143 - acc: 0.8052\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 31s 3ms/sample - loss: 0.0130 - acc: 0.8314\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 34s 3ms/sample - loss: 0.0119 - acc: 0.8549\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 37s 4ms/sample - loss: 0.0109 - acc: 0.8749\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 38s 4ms/sample - loss: 0.0101 - acc: 0.8921\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.0094 - acc: 0.9045\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.0087 - acc: 0.9130\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.0081 - acc: 0.9225\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 37s 4ms/sample - loss: 0.0076 - acc: 0.9332\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.0070 - acc: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x233dbae9e88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_test, y_test, batch_size=512, epochs = 20,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1EyKd5DcOHw"
   },
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VD_wilQPcLKW"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save(\"my_model.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9kWAvK_b84P"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17yzqpEfb8fs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKk6SIOObg-P"
   },
   "source": [
    "### Further Fun\n",
    "\n",
    "\n",
    "\n",
    "*   Experiment with different model architectures\n",
    "*   Play with different parameters such as convolution size, pooling, padding, striding, epochs, dropout etc.\n",
    "*   Train a Dense Neural Network as baseline and compare the performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Project - Image Classification.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
